# Bidirectional Path Tracing Renderer  
_C++17 / CMake / stb_image_write / tinyobjloader_

![Cornell Box – BDPT 32 spp](docs/images/cornell_box_bdpt.png)


> レイトレーシング → コサイン加重パストレーシング → Next Event Estimation → **双方向パストレーシング (BDPT)**  
> へとステップアップしながら、**BRDF 重要度サンプリング** と **Power-Heuristic MIS** を実装中。  
> “理論上の正解画像との差分がモンテカルロノイズのみ” をゴールに、独自の **差分解析パイプライン** で数値検証を行っています。  

---

## 目次
1. [概要](#概要)  
2. [前提知識](#前提) 
3. [ディレクトリ構成](#ディレクトリ)  
4. [ビルド & 実行](#ビルド)   
5. [レンダリング画像](#画像) 
6. [検証フロー](#検証)  
7. [今後のロードマップ](#今後)  
8. [参考文献](#参考文献)  
9. [ライセンス](#ライセンス)  

---

## 概要<a name="概要"></a>
長方形と球体の衝突判定を行うレンダリングをレイトレーシング → パストレーシング → NEEにて実装。また、それらを多重重点的サンプリングにて組み合わせたBDPT(双方向パストレーシング)の実装を進めている。

## 前提知識<a name="前提"></a>

## ディレクトリ構成<a name="ディレクトリ"></a>
enderer/
├─ include/             # ヘッダ (Vec3, Ray, BRDF, Object, …)
├─ src/                 # 実装 (BDPTRender, PathGenerator, …)
├─ diff/                # レンダリング結果の期待値検証
├─ docs/
│   └─ images/          # README 用スクリーンショット
├─ CMakeLists.txt
└─ README.md
### レンダリングとは
<p>CG分野におけるレンダリングとは3Dシーン、光源情報、カメラ情報を入力として2D画像を生成する処理のことを指す。</p>

<br>
<p align="center">
  <img src="https://github.com/user-attachments/assets/3e66ce3b-a197-46f9-9762-546c33d1bc4c" style="width: 70%;"><br>
  レンダリングのイメージ図
</p>
<br>
  
### レンダリング方程式
<p>
  レンダリングでは光源から放射された光が、3Dシーン上で反射、屈折し、視点に入射するまでの様子をシミュレーションすることで画像を生成する。
  ここで計算される値は放射輝度と呼ばれる、光線の強度(明るさ)を表す物理量であり、Kajiyaらによって以下の様に定式化された[1]。
</p>

$$
 L_o(x, \omega_o) = L_e(x, \omega_o) + \int_\Omega f_r(x, \omega_i, \omega_o) L_i(x, \omega_i) (\omega_i \cdot n) d\omega_i
$$

<p>
  しかし、上記の積分式は解析的に計算することができないため、コンピュータを使って数値的に計算を行っていく。
  レンダリング方程式で扱う積分式は高次元であるため、次元に依存しない積分推定が行えるモンテカルロ積分が一般的に利用される。
</p>

### モンテカルロ積分
<p>モンテカルロ積分は確率論に基づいて積分を行う手法である。  
  $X$という確率変数が確率密度関数 $p(x)$ によって集合 $\Omega$ の任意の値を取る場合、 $X$ の期待値 $E[X]$ は下記の様に表される。
</p>

$$E[X] = \int_{\Omega} xp(x)dx$$

<p>
  これは解析的に期待値を計算する方法であり、サイコロの期待値を計算する $E[X] = \frac{1}{6}(1 + 2 + 3 + 4 + 5 + 6) = 3.5$ という計算を表している(確率変数の分布が離散型か連続型かの違いはある)。
  一方で、サイコロの期待値を求める方法はもう一つ、実験的に算出する方法がある。サイコロを実際に $N$ 回振り、その出目の平均を取る方法である。各試行で得られる値を $x_i$ とすると、 $E[x_i] = E[X]$ が満たされるため、出目の平均の期待値についても解析的に算出した期待値 $E[X]$ と一致する。
</p>

$$E[\frac{1}{N}\sum_{i=1}^{N} X_i] = E[X]$$

<p>
  大数の強法則により、試行回数 $N$ が無限大に近づくにつれ、上記の左辺は右辺の $E[X]$ へと収束していく。  
  ここで伝えたいことは期待値 $E[X]$ を用いることで、積分を数値的に計算できるということである。具体的には下記の式変形を加える。
</p>

$$\int_{\Omega}f(x)dx = \int_{\Omega}\frac{f(x)}{p(x)}p(x)dx$$
$$\int_{\Omega}f(x)dx \approx \frac{1}{N}\sum_{i=1}^{N}\frac{f(X_i)}{f(X_i)}$$

<p>
  この式変形により、先ほどのレンダリング方程式の被積分関数を、確率密度関数で割り、 $N$ 回の平均を取ることで積分値を推定できる。
  ここで、確率密度関数 $p(\omega_i)$ は設計者が自由に決めることができるが、モンテカルロ推定では、確率密度関数を被積分関数に比例させるようにとることで分散を小さくすることができるため、適切な確率密度関数を取ることが非常に重要である。
</p>

### 光輸送アルゴリズムについて
- Path Tracing
  <p>
    光輸送アルゴリズムは先ほどのレンダリング方程式と組み合わせて用いる手法であり、KajiyaによってPath Tracingが提案された。
    現実世界では、光源から発せられた光が視点に入射することで、物体を視覚することができるが、光源から発せられた光の内、視点に入射するものはごくわずかであるため、Path Tracingでは視点側から光路を追跡していくことで放射輝度の計算を行う手法である。
    </p>

  <br>
  <p align="center">
    <img src="https://github.com/user-attachments/assets/c585c1e6-f93f-4b15-b208-93b66e20213d" style="width: 70%;"><br>
    Path Tracingによる光路生成イメージ
  </p>
  <br>

- Next Event Estimation
  <p>
    Path Tracingでは、視点側から物体を追跡していくため、小さい光源のシーンなどでは、視点と光源を結ぶ光路を生成することが難しく、計算効率が悪くなってしまう。
    そのため、物体との衝突ごとに、衝突点と光源を接続することで、視点側からでは中々光源につながらないようなシーンでも光路を生成することが可能となった。
    この手法をNext Event Estimation(NEE)と呼ぶ。
  </p>

  <br>
  <p align="center">
    <img src="https://github.com/user-attachments/assets/a010264f-6710-4a1a-981e-361337862a55" style="width: 70%;"><br>
    NEEによる光路生成イメージ
  </p>
  <br>

<br>
<p>
  これらの光輸送アルゴリズムには、得意、不得意なシーンが存在する。そのため、複数の手法を組み合わせることで、より複雑な光学効果が表れるシーンへの対応を図る多重重点的サンプリングと呼ばれる手法がVeachらによって提案された[2]。  
  多重重点的サンプリングではMISウエイトと呼ばれる重みを用いることで、複数の手法を組み合わせる。
</p>

## ビルド＆実行方法<a name="ビルド"></a>

### 依存ライブラリ
C++17 対応コンパイラ（例: g++-13, clang-18, MSVC 19.3+）
CMake ≥ 3.16
stb_image_write(ヘッダのみ)

git clone https://github.com/your-id/Renderer.git
cd Renderer

### CMake ビルド
mkdir build
cd build
cmake ..
cmake --build .

### レイトレーシングでレンダリング
./build/raytracing             # 出力 → results/rt.png

### コサインウェイトサンプリングを用いたパストレーシングでレンダリング
./build/cosweight              # 出力 → results/cos.png

### NEEを用いたパストレーシングでレンダリング
./build/NEE                    # 出力 → results/nee.png

### BDPTでレンダリング(実装中)
./build/bdpt                   # 出力 → results/bdpt.png

### BDPT でパス長毎にレンダリング
./build/comparePT              # 出力 → compare/length_*/

### レンダリング結果の比較
cd ../diff
./setup.sh                     # 仮想環境構築
source venv/bin/activate       # 仮想環境有効化
python3 diff.py                # BDPTとリファレンスレンダラ(コサインウェイトサンプリングPT)の比較画像生成
deactivate                     # 仮想環境終了



## レンダリング画像<a name="画像"></a>

`docs/images/` フォルダに以下のファイル名で配置してください。

| ファイル | 内容 |
| :-- | :-- |
| `rt.png` | レイトレーシングの結果 |
| `cos.png` | コサインウェイトサンプリングによるパストレーシングの結果 |
| `nee.png` | NEEを用いたパストレーシングの結果 |
| `bdpt.png` | 双方向パストレーシングの結果 |
| `abs_diff_gaussian.png` | `diff.py` による差分ヒートマップ |

## 検証フロー<a name="検証"></a>
同一シーンかつ同一のパス長においては、理論上すべてのレンダリング手法が導き出す放射輝度の期待値は一致するはずです。したがって、レンダリング結果同士の差分画像は理想的には**完全な白（差分ゼロ）**となります。

しかし実際には、モンテカルロ積分に伴うランダムノイズにより、両者の出力にはばらつきが生じます。どちらの画像に正の揺らぎ、負の揺らぎが現れるかはランダムであり、これらの差はピクセル単位で局所的に分布します。

この確率的誤差を視覚的に捉えるために、差分画像にガウシアンフィルタを適用し絶対値を取ることで、ランダムな黒い波線が浮かび上がります。これは「期待値は一致しているが、サンプル数が有限であるために生じた自然な揺らぎ」を示しており、実装の物理的正しさを視覚的に検証する強力な手段となります。


## 今後のロードマップ<a name="今後"></a>
完全なBDPTの実装

## 参考文献<a name="参考文献"></a>
| 著者               | タイトル                                                        | 備考           |
| ---------------- | ----------------------------------------------------------- | --------------    |
| Veach, E.        | *Robust Monte Carlo Methods for Light Transport Simulation* | BDPT & MIS の基礎  |
| Pharr, M. et al. | *Physically Based Rendering, 4th Ed.*                       | 実装指針全般        |
| Christophe H.    | *The Veach-style BDPT Explained*                            | PDF 変換解説       |


## ライセンス<a name="ライセンス"></a>